{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmxZYGjc7VGQKHs0051Ile"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Instructions**\n","* Runtime > Run all\n"," * select your zip files in below\n"," * the code should download the merged files"],"metadata":{"id":"8HCK1XH8dyv5"}},{"cell_type":"code","source":["#@title Processing code\n","\n","\"\"\"\n","This script merges data of the Empatica E4 into one csv file\n","\"\"\"\n","\n","__author__      = 'Yong Dich'\n","\n","import os\n","import re\n","import csv\n","import sys\n","import functools\n","import numpy as np\n","import pandas as pd\n","\n","from sys import platform\n","from copy import deepcopy\n","from itertools import chain \n","from functools import reduce\n","from datetime import datetime\n","\n","def main(d):\n","    ''' run this script in the folder of the E4 data'''\n","    \n","    # make the path into an absolute path\n","    if not os.path.isabs(d):\n","        d = os.path.abspath(d)\n","\n","    # # add the existing directories to a list\n","    # directoryList = []\n","    # if os.path.exists(directory): \n","    #     for file in os.listdir(directory): \n","    #         groupDirectory = os.path.join(directory, file)\n","    #         if os.path.isdir(groupDirectory): \n","    #             directoryList.append(groupDirectory)\n"," \n","    # # go through each directory and process its content\n","    # fileoutput = []\n","    # for d in directoryList: \n","    print(\"Processing:\", d)\n","    new_input = []\n","    input_list = direct(d)\n","    if len(input_list) > 0: \n","        for file in input_list: \n","            if file == 'ACC.csv':\n","                try: \n","                    ACC_fun(file, d) \n","                    name_of_file = file[:-4] + \"_new.csv\"\n","                    new_input.append(name_of_file)\n","                except Exception as e: \n","                    print(\"issue with the ACC file:\", e)\n","                    continue\n","            elif file == 'IBI.csv': \n","                try: \n","                    name_of_file = file[:-4] + \"_new.csv\"\n","                    IBI_fun(file, d)\n","                    new_input.append(name_of_file)\n","                except: \n","                    continue\n","            elif file == 'tags.csv':\n","                try: \n","                    name_of_file = file[:-4] + \"_new.csv\"\n","                    tagEvents(file, d)\n","                    new_input.append(name_of_file)\n","                except: \n","                    continue \n","            else:\n","                try: \n","                    dataFrames(file, d)\n","                    name_of_file = file[:-4] + \"_new.csv\"\n","                    new_input.append(name_of_file)\n","                except: \n","                    continue \n","                    \n","        if len(new_input) > 0: \n","            merge(new_input, d)\n","        else: print(\"Nothing to merge\")\n","    \n","    # probably want to merge here or check if there's a merged file\n","    fileinput = []\n","    for file in os.listdir(d): \n","        if \"Merged\" in file: \n","            #fileoutput.append(os.path.join(d,file))\n","            return os.path.join(d,file)\n","        elif \"_new\" in file: \n","            fileinput.append(file)\n","    if len(fileinput) > 0:\n","        merge(fileinput, d)\n","        \n","# return the merged files\n","#return fileoutput\n","\n","def merge(input_list, directory): \n","    data_frames = []\n","    for file in input_list: \n","        filename = os.path.join(directory, file)\n","        df1 = pd.read_table(filename, sep=',')\n","        data_frames.append(df1)\n","\n","    df_merged = reduce(lambda left, right: \n","                       pd.merge(left, right, on='unix time', how='outer'), data_frames)\n","    df_merged_sorted = df_merged.sort_values(['unix time'])\n","    \n","    # if it's not empty, let's process the tag file\n","    try:\n","        tagfile = os.path.join(directory,'tags.csv')  \n","        df = pd.read_csv(tagfile, header=None)\n","        tags = df[0][:]\n","        taglen = len(tags.values)\n","        finaltagList = []\n","        for i in range(1, taglen+1): \n","            index_tag = df_merged_sorted.index[df_merged_sorted['tags'] == \"Tag \" + str(i)]\n","            finaltagList.append((index_tag.item(), \"Tag \" + str(i)))\n","\n","        for i in range(len(finaltagList)-1):\n","            df_merged_sorted.loc[finaltagList[i][0]:finaltagList[i+1][0], 'tags']= finaltagList[i][1]\n","            if i == len(finaltagList)-2: \n","                df_merged_sorted.loc[finaltagList[i+1][0]:df_merged_sorted.last_valid_index(), 'tags']= finaltagList[i+1][1]\n","            else: continue \n","    \n","    # empty tag file\n","    except Exception as e: \n","        print('Ignoring tag file because ', e, end='; ')\n","\n","    # merge everything\n","    findSlashes = (re.findall(r'/(\\w+)', directory) or None)\n","    name = findSlashes[len(findSlashes)-1] + 'Merged.csv'\n","    df_merged_sorted.to_csv(os.path.join(directory, name), sep=',', na_rep='', index=False)\n","\n","\n","def direct(directory): \n","    input_list = []\n","    original_length = len(os.listdir(directory))\n","    acceptablefiles = [\"ACC\", \"BVP\", \"EDA\", \"HR\", \"IBI\", \"tags\", \"TEMP\"]\n","    if os.path.exists(directory): \n","        for file in os.listdir(directory): \n","            checkFile = file[:-4] + \"_new.csv\"\n","            if checkFile in os.listdir(directory):\n","                print(\"Already have \" + checkFile)\n","                continue\n","            else: \n","                if ('_new' not in file) and file.endswith(\".csv\") and any(word in file for word in acceptablefiles):\n","                    input_list.append(file)\n","                    \n","    return input_list\n","\n","def ACC_fun(filename, directory): \n","    file = os.path.join(directory, filename) \n","    df = pd.read_csv(file, header=None)\n","    \n","    initialx = df.loc[0,0]\n","    initialy = df.loc[0,1]\n","    initialz = df.loc[0,2]\n","\n","    numx = df[0][2:]\n","    numy = df[1][2:]\n","    numz = df[2][2:]\n","    hertzx = df[0][1]\n","    hertzy = df[1][1]\n","    hertzz = df[2][1]\n","\n","    # print another\n","    file_n = filename[:-4]\n","    final_file_n = file_n + ' real time'\n","    new_data = {\n","        'unix time' :[], \n","        final_file_n : [], \n","        'ACC_x': [], \n","        'ACC_y':[], \n","        'ACC_z':[]\n","    }\n","    sampleNumber = 0\n","    for item in numx: \n","        if (hertzx) or (initialx):\n","            pass\n","        # else: \n","        new_data['ACC_x'].append(item)\n","        newcolumn = float(sampleNumber)/hertzx + initialx \n","        sampleNumber = sampleNumber + 1\n","        new_data['unix time'].append(newcolumn)\n","        realtime = datetime.datetime.fromtimestamp(newcolumn).strftime('%Y-%m-%d %H:%M:%S')\n","        new_data[final_file_n].append(realtime)\n","    for item in numy: \n","        if (hertzy) or (initialy):\n","            pass\n","        # else: \n","        new_data['ACC_y'].append(item)\n","    for item in numz: \n","        if (hertzz) or (initialz):\n","            pass\n","        # else: \n","        new_data['ACC_z'].append(item)\n","\n","    unix_df = pd.DataFrame(new_data)\n","\n","    name_of_file = file[:-4] + \"_new.csv\"\n","    unix_df.to_csv(os.path.join(directory, name_of_file), \n","                   header=True, index=False, encoding='utf-8', mode='a')\n","\n","\n","def IBI_fun(filename, directory): \n","    file = os.path.join(directory, filename)  \n","    df = pd.read_csv(file, header=None)\n","    ibi = df[1][1:]\n","    initial = df[0][0]\n","    times_from_initial = df[0][1:]\n","    file_n = filename[:-4]\n","    final_file_n = file_n + ' real time'\n","    new_data = {\n","        'unix time': [], \n","        final_file_n: [], \n","        file_n: []\n","    }\n","    \n","    for item in ibi: \n","        new_data[file_n].append(item)\n","    \n","    \n","    for time in times_from_initial: \n","        newunix = initial + time\n","    \n","        new_data['unix time'].append(newunix)\n","        realtime = datetime.datetime.fromtimestamp(newunix).strftime('%Y-%m-%d %H:%M:%S')\n","        new_data[final_file_n].append(realtime)\n","    unix_df = pd.DataFrame(new_data)\n","    name_of_file = file[:-4] + \"_new.csv\"\n","    unix_df.to_csv(os.path.join(directory, name_of_file), \n","                   header=True, index=False, encoding='utf-8', mode='a')\n","    \n","def tagEvents(filename, directory): \n","    # read in the file as dataframe\n","    file = os.path.join(directory, filename)  \n","    df = pd.read_csv(file, header=None)\n","    file_n = filename[:-4]\n","    final_file_n = file_n + ' real time'\n","    tags = df[0][:]\n","    new_data = {    \n","        'unix time': [], \n","        file_n: [], \n","        final_file_n: []\n","    }\n","\n","    # could also have enumerate(tags) for index and values \n","    tagNum = 1\n","    for tag in tags: \n","        new_data['unix time'].append(tag)\n","        new_data[file_n].append(\"Tag \" + str(tagNum))\n","        realtime = datetime.datetime.fromtimestamp(tag).strftime('%Y-%m-%d %H:%M:%S')\n","        new_data[final_file_n].append(realtime)\n","        tagNum += 1\n","    unix_df = pd.DataFrame(new_data)\n","    name_of_file = file[:-4] + \"_new.csv\"\n","\n","    unix_df.to_csv(os.path.join(directory, name_of_file), \n","                   header=True, index=False, encoding='utf-8', mode='a')\n","\n","def dataFrames(filename, directory):\n","    file = os.path.join(directory, filename)  \n","    df = pd.read_csv(file, header=None)\n","    file_n = filename[:-4]\n","    final_file_n = file_n + ' real time'\n","\n","    unixtime = df[0][0]\n","    freq = df[0][1]\n","    fileItems = df[0][2:]\n","\n","    new_data = { \n","        'unix time' : [],\n","        file_n : [], \n","        final_file_n : []\n","    }\n","    \n","    sampleNumber = 0\n","    for item in fileItems: \n","        new_data[file_n].append(item)\n","        newcolumn = float(sampleNumber)/freq + unixtime \n","        sampleNumber = sampleNumber + 1\n","        new_data['unix time'].append(newcolumn)\n","        realtime = datetime.datetime.fromtimestamp(newcolumn).strftime('%Y-%m-%d %H:%M:%S')\n","        new_data[final_file_n].append(realtime)\n","\n","    df = pd.DataFrame(new_data)\n","    name_of_file = file[:-4] + \"_new.csv\"\n","    df.to_csv(os.path.join(directory, name_of_file), \n","              header=True, index=False, encoding='utf-8', mode='a')\n","    \n"],"metadata":{"cellView":"form","id":"Z0V7GYmArtbi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"OyrVgtzKdLr5"},"outputs":[],"source":["#@title Upload your zip file\n","from google.colab import files\n","import pandas as pd\n","import datetime\n","import os\n","\n","# get the file\n","content = files.upload()\n","for filename in list(content.keys()):\n","\n","  # make sure the filename is unique\n","  now = str(datetime.datetime.now())\n","  now = filename + '_' + now\n","  unique_filename = filename.replace('.csv', '-' + now + '.csv')\n","  os.rename(filename, unique_filename)\n","\n","  # unzip the data into a new folder\n","  ! mkdir \"$now\"\n","  ! unzip \"$unique_filename\" -d \"$now\"\n","\n","  # process the data\n","  output = main(now)\n","  files.download(output)"]}]}